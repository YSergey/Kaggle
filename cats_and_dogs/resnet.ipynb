{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "base_dir = '/Volumes/KESU/dog_vs_cat'\n",
    "dataset = os.path.join(base_dir, 'dataset')\n",
    "os.mkdir(dataset)\n",
    "\n",
    "train_dir = os.path.join(dataset, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(dataset, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.mkdir(train_cats_dir)\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_dogs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainデータの８割を学習用、残りをバリデーション用として使用する\n",
    "#total number of images 12500 \n",
    "#train images 10000\n",
    "#validation images 2500\n",
    "\n",
    "fnames_cat = ['cat.{}.jpg'.format(i) for i in range(12500)]\n",
    "fnames_dog = ['dog.{}.jpg'.format(i) for i in range(12500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重複を許さず、猫ファイル名を取得\n",
    "import random\n",
    "\n",
    "# 乱数により移動先を振り分け\n",
    "train = os.path.join(base_dir, 'train')\n",
    "\n",
    "for cat in fnames_cat:\n",
    "    src = os.path.join(train, cat)\n",
    "    if random.random() >= 0.2: \n",
    "        # 学習用フォルダへ移動\n",
    "        dst = os.path.join(train_cats_dir,cat)\n",
    "        shutil.copy(src,dst)\n",
    "    else:                      \n",
    "        dst = os.path.join(validation_cats_dir,cat)\n",
    "        shutil.copy(src,dst)\n",
    "\n",
    "for dog in fnames_dog:\n",
    "    src = os.path.join(train, dog)\n",
    "    if random.random() >= 0.2: \n",
    "        # 学習用フォルダへ移動\n",
    "        dst = os.path.join(train_dogs_dir,dog)\n",
    "        shutil.copy(src,dst)\n",
    "    else:                      \n",
    "        # dir2へ移動\n",
    "        dst = os.path.join(validation_dogs_dir,dog)\n",
    "        shutil.copy(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, add, GlobalAveragePooling2D\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import toimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shortcut(inputs, residual):\n",
    "  n_filters = residual._keras_shape[3]\n",
    "  shortcut = Convolution2D(n_filters, (1,1), strides=(1,1),kernel_initializer='he_normal', padding='valid')(inputs)\n",
    "                           \n",
    "  return add([shortcut, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resblock(n_filters, strides=(1,1)):\n",
    "    def f(input):\n",
    "        x = Convolution2D(n_filters, (3,3), strides=strides,kernel_initializer='he_normal', padding='same')(input)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Convolution2D(n_filters, (3,3), strides=strides,kernel_initializer='he_normal', padding='same')(input)\n",
    "        x = BatchNormalization()(x)\n",
    "        return _shortcut(input, x)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet():\n",
    "  inputs = Input(shape=(150, 150, 3))\n",
    "  x = Convolution2D(32, (7,7), strides=(1,1),kernel_initializer='he_normal', padding='same')(inputs)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  \n",
    "  x = MaxPooling2D((3, 3), strides=(2,2), padding='same')(x)\n",
    "  \n",
    "  \n",
    "  x = _resblock(n_filters=64)(x)\n",
    "  x = _resblock(n_filters=64)(x)\n",
    "  x = _resblock(n_filters=64)(x)\n",
    "  x = MaxPooling2D(strides=(2,2))(x)  \n",
    "  x = _resblock(n_filters=128)(x)\n",
    "  x = _resblock(n_filters=128)(x) \n",
    "  x = _resblock(n_filters=128)(x)\n",
    "\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(1, kernel_initializer='he_normal', activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs=inputs, outputs=x)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 150, 150, 32) 4736        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 150, 150, 32) 128         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 150, 150, 32) 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 75, 75, 32)   0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 75, 75, 64)   18496       max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 75, 75, 64)   2112        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 75, 75, 64)   256         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 75, 75, 64)   0           conv2d_120[0][0]                 \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 75, 75, 64)   36928       add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 75, 75, 64)   4160        add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 75, 75, 64)   256         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 75, 75, 64)   0           conv2d_123[0][0]                 \n",
      "                                                                 batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 75, 75, 64)   36928       add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 75, 75, 64)   4160        add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 75, 75, 64)   256         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 75, 75, 64)   0           conv2d_126[0][0]                 \n",
      "                                                                 batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 37, 37, 64)   0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 37, 37, 128)  73856       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 37, 37, 128)  8320        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 37, 37, 128)  512         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 37, 37, 128)  0           conv2d_129[0][0]                 \n",
      "                                                                 batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 37, 37, 128)  147584      add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 37, 37, 128)  16512       add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 37, 37, 128)  512         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 37, 37, 128)  0           conv2d_132[0][0]                 \n",
      "                                                                 batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 37, 37, 128)  147584      add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 37, 37, 128)  16512       add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 37, 37, 128)  512         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 37, 37, 128)  0           conv2d_135[0][0]                 \n",
      "                                                                 batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 128)          0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            129         global_average_pooling2d_7[0][0] \n",
      "==================================================================================================\n",
      "Total params: 520,449\n",
      "Trainable params: 519,233\n",
      "Non-trainable params: 1,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = resnet()\n",
    "\n",
    "adam = Adam()\n",
    "\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "base_dir = '/Volumes/KESU/dog_vs_cat'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = os.path.join(dataset,'train')\n",
    "validation = os.path.join(dataset,'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = os.path.join(base_dir, 'dataset')\n",
    "#os.mkdir(os.path.join(dataset, 'train'))\n",
    "#os.mkdir(os.path.join(dataset, 'validation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training  images 3\n",
      "///////////////////////////////////////////////////\n",
      "total validation  images 3\n",
      "total test images 3\n"
     ]
    }
   ],
   "source": [
    "print('total training  images', len(os.listdir(train)))\n",
    "print('///////////////////////////////////////////////////')\n",
    "print('total validation  images', len(os.listdir(validation)))\n",
    "print('total test images', len(os.listdir(validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20133 images belonging to 2 classes.\n",
      "Found 4867 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "#画像ファイルを読み込む\n",
    "#RGBのピクセルグリッドにデコードする\n",
    "#テンソルに変換する\n",
    "#[0, 1]に収まるようにする\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "val_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_data_generator.flow_from_directory(\n",
    "                                    train, \n",
    "                                    target_size=(150,150), \n",
    "                                    batch_size=32, \n",
    "                                    class_mode='binary')\n",
    "\n",
    "val_generator = val_data_generator.flow_from_directory(\n",
    "                                    validation, \n",
    "                                    target_size=(150,150), \n",
    "                                    batch_size=32, \n",
    "                                    class_mode='binary')\n",
    "\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "                                    test_dir, \n",
    "                                    target_size=(150,150), \n",
    "                                    batch_size=32, \n",
    "                                    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "                             optimizer= optimizers.RMSprop(lr=1e-3), \n",
    "                             metrics= ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape (32, 150, 150, 3)\n",
      "/////////////////////////////////\n",
      "labels batch size (32,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape', data_batch.shape)\n",
    "    print('/////////////////////////////////')\n",
    "    print('labels batch size', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "callback_cp = ModelCheckpoint(filepath='weights.{epoch:02d}.hdf5')\n",
    "callback_es = EarlyStopping(monitor='val_acc', patience=2, mode='auto', verbose=1)\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                                                     steps_per_epoch=30, \n",
    "                                                     epochs=30, \n",
    "                                                     validation_data=val_generator, \n",
    "                                                     callbacks=[callback_cp, callback_es],\n",
    "                                                     validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
